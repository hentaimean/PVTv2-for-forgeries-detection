{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T16:54:25.872270500Z",
     "start_time": "2023-07-28T16:54:10.876829700Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nexty\\anaconda3\\envs\\PVT\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['LOCAL_RANK'] = '0'\n",
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv.cnn.utils import revert_sync_batchnorm\n",
    "from mmcv.utils import Config, get_git_hash\n",
    "\n",
    "from mmseg import __version__\n",
    "from mmseg.apis import set_random_seed, train_segmentor\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.utils import (get_device, get_root_logger, setup_multi_processes)\n",
    "\n",
    "import pvt, pvtv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfg_path = '../my_configs/fpn_pvtv2_b5_casia512_320k.py'\n",
    "cfg = Config.fromfile(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 00:14:49,777 - mmseg - INFO - OpenCV num_threads is `16\n",
      "2023-07-29 00:14:49,777 - mmseg - INFO - Distributed training: False\n",
      "2023-07-29 00:14:49,940 - mmseg - INFO - Config:\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook', by_epoch=False),\n",
      "        dict(type='TensorboardLoggerHook')\n",
      "    ])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "find_unused_parameters = True\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='pretrained/pvt_v2_b5.pth',\n",
      "    backbone=dict(type='pvt_v2_b5', style='pytorch'),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[64, 128, 320, 512],\n",
      "        out_channels=256,\n",
      "        num_outs=4),\n",
      "    decode_head=dict(\n",
      "        type='FPNHead',\n",
      "        in_channels=[256, 256, 256, 256],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        feature_strides=[4, 8, 16, 32],\n",
      "        channels=128,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        out_channels=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=[\n",
      "            dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "            dict(type='DiceLoss', use_sigmoid=True, loss_weight=1.0)\n",
      "        ]),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'CasiaDataset'\n",
      "data_root = '../train_dataset'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (512, 512)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(\n",
      "        type='PhotoMetricDistortion',\n",
      "        brightness_delta=10,\n",
      "        contrast_range=(0.9, 1.2),\n",
      "        saturation_range=(0.8, 1.2),\n",
      "        hue_delta=10),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(type='Pad', size=(512, 512)),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=50,\n",
      "        dataset=dict(\n",
      "            type='CasiaDataset',\n",
      "            data_root='../train_dataset',\n",
      "            img_dir='train/images',\n",
      "            ann_dir='train/gt_normed',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(2048, 512),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(512, 512),\n",
      "                    cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(\n",
      "                    type='PhotoMetricDistortion',\n",
      "                    brightness_delta=10,\n",
      "                    contrast_range=(0.9, 1.2),\n",
      "                    saturation_range=(0.8, 1.2),\n",
      "                    hue_delta=10),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "            ])),\n",
      "    val=dict(\n",
      "        type='CasiaDataset',\n",
      "        data_root='../train_dataset',\n",
      "        img_dir='val/images',\n",
      "        ann_dir='val/gt_normed',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(type='Pad', size=(512, 512)),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CasiaDataset',\n",
      "        data_root='../train_dataset',\n",
      "        img_dir='test/images',\n",
      "        ann_dir='test/gt_normed',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(type='Pad', size=(512, 512)),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            pos_block=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            head=dict(lr_mult=10.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=320000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=5000)\n",
      "evaluation = dict(interval=5000, metric='mIoU')\n",
      "work_dir = '../work_dirs/casia512_320k/fpn_pvtv2_b5'\n",
      "gpu_ids = range(0, 4)\n",
      "auto_resume = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "cfg.work_dir = '../work_dirs/casia512_320k/fpn_pvtv2_b5'\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "setup_multi_processes(cfg)\n",
    "meta = dict()\n",
    "\n",
    "distributed = False\n",
    "\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = get_device()\n",
    "seed = cfg.seed\n",
    "meta['seed'] = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nexty\\desktop\\pvtv2-seg\\mmsegmentation\\mmseg\\models\\decode_heads\\decode_head.py:120: UserWarning: threshold is not defined for binary, and defaultsto 0.3\n",
      "  warnings.warn('threshold is not defined for binary, and defaults'\n",
      "c:\\users\\nexty\\desktop\\pvtv2-seg\\mmsegmentation\\mmseg\\models\\losses\\cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "2023-07-29 00:14:51,280 - mmseg - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2023-07-29 00:14:51,290 - mmseg - INFO - initialize FPNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2023-07-29 00:14:51,298 - mmseg - INFO - EncoderDecoder(\n",
      "  (backbone): pvt_v2_b5(\n",
      "    (patch_embed1): OverlapPatchEmbed(\n",
      "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (block1): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.002)\n",
      "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.004)\n",
      "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
      "    (patch_embed2): OverlapPatchEmbed(\n",
      "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (block2): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.006)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.008)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.010)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.012)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.014)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.016)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    (patch_embed3): OverlapPatchEmbed(\n",
      "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (block3): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.018)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.020)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.022)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.024)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.025)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.027)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.029)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.031)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.033)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.035)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.037)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.039)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (12): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.041)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (13): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.043)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (14): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.045)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (15): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.047)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (16): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.049)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (17): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.051)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (18): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.053)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (19): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.055)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (20): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.057)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (21): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.059)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (22): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.061)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (23): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.063)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (24): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.065)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (25): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.067)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (26): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.069)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (27): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.071)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (28): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.073)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (29): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.075)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (30): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.076)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (31): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.078)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (32): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.080)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (33): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.082)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (34): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.084)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (35): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.086)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (36): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.088)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (37): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.090)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (38): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.092)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (39): Block(\n",
      "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.094)\n",
      "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
      "    (patch_embed4): OverlapPatchEmbed(\n",
      "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (block4): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.096)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.098)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): DropPath(drop_prob=0.100)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dwconv): DWConv(\n",
      "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "          )\n",
      "          (act): GELU()\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (neck): FPN(\n",
      "    (lateral_convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (fpn_convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "  (decode_head): FPNHead(\n",
      "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
      "    (loss_decode): ModuleList(\n",
      "      (0): CrossEntropyLoss(avg_non_ignore=False)\n",
      "      (1): DiceLoss()\n",
      "    )\n",
      "    (conv_seg): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (scale_heads): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Upsample()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Upsample()\n",
      "        (2): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Upsample()\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Upsample()\n",
      "        (2): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Upsample()\n",
      "        (4): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Upsample()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_segmentor(\n",
    "        cfg.model,\n",
    "        train_cfg=cfg.get('train_cfg'),\n",
    "        test_cfg=cfg.get('test_cfg'))\n",
    "model.init_weights()\n",
    "if not distributed:\n",
    "    model = revert_sync_batchnorm(model)\n",
    "logger.info(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 00:14:51,410 - mmseg - INFO - Loaded 4084 images\n"
     ]
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    val_dataset.pipeline = cfg.data.train.pipeline\n",
    "    datasets.append(build_dataset(val_dataset))\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.checkpoint_config is not None:\n",
    "        # save mmseg version, config file content and class names in\n",
    "        # checkpoints as meta data\n",
    "    cfg.checkpoint_config.meta = dict(\n",
    "        mmseg_version=f'{__version__}+{get_git_hash()[:7]}',\n",
    "        config=cfg.pretty_text,\n",
    "        CLASSES=datasets[0].CLASSES,\n",
    "        PALETTE=datasets[0].PALETTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 00:14:51,952 - mmseg - INFO - Loaded 511 images\n",
      "2023-07-29 00:14:51,952 - mmseg - INFO - Start running, host: hentaimean@Aorus-Elite, work_dir: C:\\Users\\nexty\\Desktop\\PVTv2-Seg\\work_dirs\\casia512_320k\\fpn_pvtv2_b5\n",
      "2023-07-29 00:14:51,952 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      " -------------------- \n",
      "2023-07-29 00:14:51,960 - mmseg - INFO - workflow: [('train', 1)], max: 320000 iters\n",
      "2023-07-29 00:14:51,960 - mmseg - INFO - Checkpoints will be saved to C:\\Users\\nexty\\Desktop\\PVTv2-Seg\\work_dirs\\casia512_320k\\fpn_pvtv2_b5 by HardDiskBackend.\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "train_segmentor(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=distributed,\n",
    "        validate=True,\n",
    "        timestamp=timestamp,\n",
    "        meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
