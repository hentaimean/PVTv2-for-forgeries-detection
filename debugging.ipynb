{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T22:29:17.189153Z",
     "start_time": "2025-11-23T22:29:13.839327Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from splits.splits import split_dataset_by_groups\n",
    "from model.pvtv2 import PVTv2B5ForForgerySegmentation\n",
    "from tools.dataclass import *\n",
    "from tools.loss import BinaryCrossEntropyLoss, DiceLoss, FocalLoss\n",
    "from tools.optimizer import create_optimizer\n",
    "from tools.scheduler import create_scheduler\n",
    "from tools.metrics import BinarySegmentationMetrics\n",
    "from tools.visualize import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:29:17.219705Z",
     "start_time": "2025-11-23T22:29:17.207186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Dataset ---\n",
    "IMAGE_DIR = 'images'\n",
    "MASKS_DIR = 'masks'\n",
    "SPLIT_PATH=\"splits/grouped_indices.pt\"\n",
    "\n",
    "# --- DataLoader ---\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "SHUFFLE_TRAIN = True\n",
    "SHUFFLE_VAL = False\n",
    "PIN_MEMORY = True  # ускоряет передачу на GPU\n",
    "DROP_LAST = True   # для стабильности batch-norm при малых батчах\n",
    "\n",
    "# --- Configuration ---\n",
    "MAX_ITERS = 320000\n",
    "VAL_INTERVAL = 5000\n",
    "SAVE_INTERVAL = 5000\n",
    "LOG_INTERVAL = 50\n",
    "VISUALIZE_EVERY = 1"
   ],
   "id": "4becaddcbdd6a89a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:15.589950Z",
     "start_time": "2025-11-23T22:29:17.440078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обучающий датасет с аугментациями и foreground-aware кропами\n",
    "train_dataset_full = ForgerySegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    transform=get_training_augmentation(),\n",
    "    fg_crop_prob=0.7,           # ← кропы с подделками\n",
    "    crop_size=(512, 512),\n",
    "    use_albumentations=True\n",
    ")\n",
    "\n",
    "# Валидационный датасет БЕЗ аугментаций, НО С кропами (фиксированный размер)\n",
    "eval_dataset_full = ForgerySegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    transform=get_validation_augmentation(),\n",
    "    fg_crop_prob=0.0,          \n",
    "    crop_size=(512, 512),     \n",
    "    use_albumentations=True\n",
    ")"
   ],
   "id": "ac04648b84cac5d8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:15.636514Z",
     "start_time": "2025-11-23T22:30:15.621996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Разбитие датасета \n",
    "# \n",
    "# # Получаем индексы один раз (на основе имён файлов — одинаковы в обоих датасетах)\n",
    "# train_idx, val_idx, test_idx = split_dataset_by_groups(\n",
    "#     dataset=train_dataset_full,\n",
    "#     save_path=SPLIT_PATH\n",
    "# )"
   ],
   "id": "504508529fc9745e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:16.549809Z",
     "start_time": "2025-11-23T22:30:15.648542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загружаем сохранённые индексы\n",
    "split_data = torch.load(SPLIT_PATH)\n",
    "\n",
    "train_indices = split_data['train_indices']\n",
    "val_indices = split_data['val_indices']\n",
    "test_indices = split_data['test_indices']\n",
    "seed = split_data.get('seed', 'unknown')\n",
    "\n",
    "print(f\"  Train: {len(train_indices)}\")\n",
    "print(f\"  Val:   {len(val_indices)}\")\n",
    "print(f\"  Test:  {len(test_indices)}\")"
   ],
   "id": "8cc00b85833cb8b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: 216602\n",
      "  Val:   5972\n",
      "  Test:  5925\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:16.581361Z",
     "start_time": "2025-11-23T22:30:16.566835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаём подвыборки\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset = Subset(eval_dataset_full, val_indices)\n",
    "test_dataset = Subset(eval_dataset_full, test_indices)"
   ],
   "id": "8b6c7129bc797e78",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:16.659974Z",
     "start_time": "2025-11-23T22:30:16.598380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "item = train_dataset[34534]\n",
    "\n",
    "print(item['image'].shape)\n",
    "print(item['mask'].shape)\n",
    "\n",
    "print(item['image'].dtype)\n",
    "print(item['mask'].dtype)\n",
    "print(item['img_path'])\n",
    "print(item['mask_path'])"
   ],
   "id": "83e5f1ed61b947ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "torch.Size([512, 512])\n",
      "torch.float32\n",
      "torch.int64\n",
      "F:\\Datasets\\DEFACTO\\images\\orig_000000546762.jpg\n",
      "F:\\Datasets\\DEFACTO\\masks\\orig_000000546762.tif\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:22.154860Z",
     "start_time": "2025-11-23T22:30:16.692527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PVTv2B5ForForgerySegmentation(img_size=512)\n",
    "model = model.float()\n",
    "model"
   ],
   "id": "b847999bd44da03d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PVTv2B5ForForgerySegmentation(\n",
       "  (backbone): pvt_v2_b5(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0-39): 40 x Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decode_head): FPNHead(\n",
       "    (scale_heads): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (conv_seg): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:22.439159Z",
     "start_time": "2025-11-23T22:30:22.187910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загружаем чекпоинт\n",
    "checkpoint_path = \"model/pvt_v2_b5.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "# Удаляем классификационную голову (не нужна для сегментации)\n",
    "keys_to_remove = [k for k in state_dict.keys() if k.startswith('head')]\n",
    "for k in keys_to_remove:\n",
    "    del state_dict[k]\n",
    "\n",
    "# Загружаем в backbone\n",
    "missing_keys, unexpected_keys = model.backbone.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Проверяем, что всё ок\n",
    "if len(unexpected_keys) == 0 and all('head' not in k for k in missing_keys):\n",
    "    print(\"Предобученные веса PVTv2-B5 успешно загружены!\")\n",
    "    if missing_keys:\n",
    "        print(f\"Не загружены ключи (ожидаемо для head): {missing_keys}\")\n",
    "else:\n",
    "    print(\"Ошибка при загрузке весов:\")\n",
    "    print(\"Unexpected keys:\", unexpected_keys)\n",
    "    print(\"Missing keys:\", missing_keys)"
   ],
   "id": "b7157ea1c9a998da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предобученные веса PVTv2-B5 успешно загружены!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:26.850930Z",
     "start_time": "2025-11-23T22:30:25.593179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bce_loss_fn = BinaryCrossEntropyLoss(loss_weight=1.0, avg_non_ignore=True)\n",
    "dice_loss_fn = DiceLoss(loss_weight=1.0, use_sigmoid=True)\n",
    "focal_loss_fn = FocalLoss(loss_weight=1.0)  # опционально\n",
    "\n",
    "optimizer = create_optimizer(\n",
    "    model,\n",
    "    lr=6e-5,\n",
    "    weight_decay=0.01,\n",
    "    head_lr_mult=10.0\n",
    ")\n",
    "\n",
    "# Планировщик\n",
    "scheduler = create_scheduler(\n",
    "    optimizer,\n",
    "    warmup_iters=1500,\n",
    "    total_iters=320000,\n",
    "    min_lr=0.0,\n",
    "    power=1.0\n",
    ")"
   ],
   "id": "758e843b3e89fe76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры разбиты на группы:\n",
      "   Backbone: 746 параметров\n",
      "   Norm:     322 параметров\n",
      "   Head:     30 параметров\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:26.882485Z",
     "start_time": "2025-11-23T22:30:26.869972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=SHUFFLE_TRAIN,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    drop_last=DROP_LAST\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=SHUFFLE_VAL,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    drop_last=False  # на валидации лучше сохранять все примеры\n",
    ")"
   ],
   "id": "59e2395bf8c1ef57",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:30:54.046514Z",
     "start_time": "2025-11-23T22:30:28.459229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = f\"runs/forgery_pvtv2_b5_{timestamp}\"\n",
    "checkpoint_dir = f\"{run_dir}/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=run_dir)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "train_iter = iter(train_loader)\n",
    "metrics_val = BinarySegmentationMetrics(threshold=0.5)\n",
    "\n",
    "best_iou = 0.0"
   ],
   "id": "3f0f6bd53404540e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:32:03.122939Z",
     "start_time": "2025-11-23T22:30:55.687911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pbar = tqdm(range(1, MAX_ITERS + 1), desc=\"Training\", mininterval=1.0)\n",
    "\n",
    "for iter_idx in pbar:\n",
    "\n",
    "    # --- Обучение ---\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    try:\n",
    "        batch = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        batch = next(train_iter)\n",
    "\n",
    "    # МАСКА: float32 + канал → [B, 1, H, W]\n",
    "    images = batch['image'].to(device, non_blocking=True)\n",
    "    masks = batch['mask'].to(device, non_blocking=True).float().unsqueeze(1)\n",
    "    \n",
    "    assert images.dtype == torch.float32, f\"Expected float32, got {images.dtype}\"\n",
    "    assert masks.dtype == torch.float32, f\"Expected float32, got {masks.dtype}\"\n",
    "\n",
    "    pred = model(images)\n",
    "    \n",
    "    # Считаем каждую потерю отдельно\n",
    "    loss_bce = bce_loss_fn(pred, masks)\n",
    "    loss_dice = dice_loss_fn(pred, masks)\n",
    "    loss_focal = focal_loss_fn(pred, masks)\n",
    "    total_loss = 0.5 * loss_bce + 1.0 * loss_dice + 2 * loss_focal\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- Логирование в TensorBoard ---\n",
    "    if iter_idx % LOG_INTERVAL == 0:\n",
    "        writer.add_scalar('Loss/BCE', loss_bce.item(), iter_idx)\n",
    "        writer.add_scalar('Loss/Dice', loss_dice.item(), iter_idx)\n",
    "        writer.add_scalar('Loss/Focal', loss_focal.item(), iter_idx)\n",
    "        writer.add_scalar('Loss/Total', total_loss.item(), iter_idx)\n",
    "        writer.add_scalar('Train/LR', optimizer.param_groups[0]['lr'], iter_idx)\n",
    "\n",
    "    # --- Обновление tqdm (каждые 100 итераций) ---\n",
    "    if iter_idx % 100 == 0:\n",
    "        pbar.set_postfix({\n",
    "            'BCE': f\"{loss_bce.item():.3f}\",\n",
    "            'Dice': f\"{loss_dice.item():.3f}\",\n",
    "            'Focal': f\"{loss_focal.item():.3f}\",\n",
    "            'Total': f\"{total_loss.item():.3f}\",\n",
    "            'LR': f\"{optimizer.param_groups[0]['lr']:.1e}\"\n",
    "        })\n",
    "\n",
    "    # --- Валидация ---\n",
    "    if iter_idx % VAL_INTERVAL == 0:\n",
    "        val_metrics, val_loss = validate_epoch(\n",
    "            model, val_loader, metrics_val, device,\n",
    "            writer=writer,\n",
    "            global_step=iter_idx\n",
    "        )\n",
    "\n",
    "        for name, value in val_metrics.items():\n",
    "            writer.add_scalar(f'Val/{name}', value, iter_idx)\n",
    "\n",
    "        print(f\"\\n[Iter {iter_idx}] Val — \" + \n",
    "              \" | \".join(f\"{k}: {v:.4f}\" for k, v in val_metrics.items()))\n",
    "\n",
    "        # --- Сохранение ЛУЧШЕЙ модели ---\n",
    "        current_iou = val_metrics['IoU_forgery']\n",
    "        if current_iou > best_iou:\n",
    "            best_iou = current_iou\n",
    "            best_path = f\"{checkpoint_dir}/best_model_iou_{current_iou:.4f}_iter_{iter_idx}.pth\"\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"Новая лучшая модель сохранена: {os.path.basename(best_path)}\")\n",
    "\n",
    "    # --- Сохранение ПОСЛЕДНЕЙ модели (каждые 10k) ---\n",
    "    if iter_idx % SAVE_INTERVAL == 0:\n",
    "        last_path = f\"{checkpoint_dir}/last_model_iter_{iter_idx}.pth\"\n",
    "        torch.save(model.state_dict(), last_path)\n",
    "\n",
    "# --- Финальное сохранение последней модели ---\n",
    "final_path = f\"{checkpoint_dir}/last_model_final.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "writer.close()"
   ],
   "id": "c7f5136b997b167e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 199/320000 [01:07<29:58:26,  2.96it/s, BCE=1.725, Dice=0.999, Focal=0.042, Total=1.945, LR=4.0e-06]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 30\u001B[0m\n\u001B[0;32m     27\u001B[0m loss_focal \u001B[38;5;241m=\u001B[39m focal_loss_fn(pred, masks)\n\u001B[0;32m     28\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m loss_bce \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m*\u001B[39m loss_dice \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m loss_focal\n\u001B[1;32m---> 30\u001B[0m \u001B[43mtotal_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     32\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\_tensor.py:625\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    617\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    618\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    623\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    624\u001B[0m     )\n\u001B[1;32m--> 625\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    349\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    351\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 354\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    839\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    840\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 841\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    842\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    843\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    844\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    845\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:32:18.038065Z",
     "start_time": "2025-11-23T22:32:18.023060Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "35fc3c7b49cb0a7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
