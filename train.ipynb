{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T21:26:16.520527Z",
     "start_time": "2025-11-23T21:26:13.081247Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from splits.splits import split_dataset_by_groups\n",
    "from model.pvtv2 import PVTv2B5ForForgerySegmentation\n",
    "from tools.dataclass import *\n",
    "from tools.loss import BinaryCrossEntropyLoss, DiceLoss, FocalLoss\n",
    "from tools.optimizer import create_optimizer\n",
    "from tools.scheduler import create_scheduler\n",
    "from tools.metrics import BinarySegmentationMetrics\n",
    "from tools.visualize import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:26:16.551584Z",
     "start_time": "2025-11-23T21:26:16.543066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Dataset ---\n",
    "IMAGE_DIR = 'images'\n",
    "MASKS_DIR = 'masks'\n",
    "SPLIT_PATH=\"splits/grouped_indices.pt\"\n",
    "\n",
    "# --- DataLoader ---\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "SHUFFLE_TRAIN = True\n",
    "SHUFFLE_VAL = False\n",
    "PIN_MEMORY = True  # ускоряет передачу на GPU\n",
    "DROP_LAST = True   # для стабильности batch-norm при малых батчах\n",
    "\n",
    "# --- Configuration ---\n",
    "MAX_ITERS = 320000\n",
    "VAL_INTERVAL = 5000\n",
    "SAVE_INTERVAL = 5000\n",
    "LOG_INTERVAL = 100\n",
    "VISUALIZE_EVERY = 1"
   ],
   "id": "4becaddcbdd6a89a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:16.448450Z",
     "start_time": "2025-11-23T21:26:16.563096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Обучающий датасет с аугментациями и foreground-aware кропами\n",
    "train_dataset_full = ForgerySegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    transform=get_training_augmentation(),\n",
    "    fg_crop_prob=0.7,           # ← кропы с подделками\n",
    "    crop_size=(512, 512),\n",
    "    use_albumentations=True\n",
    ")\n",
    "\n",
    "# Валидационный датасет БЕЗ аугментаций, НО С кропами (фиксированный размер)\n",
    "eval_dataset_full = ForgerySegmentationDataset(\n",
    "    images_dir=IMAGE_DIR,\n",
    "    masks_dir=MASKS_DIR,\n",
    "    transform=get_validation_augmentation(),\n",
    "    fg_crop_prob=0.0,          \n",
    "    crop_size=(512, 512),     \n",
    "    use_albumentations=True\n",
    ")"
   ],
   "id": "ac04648b84cac5d8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:16.636698Z",
     "start_time": "2025-11-23T21:27:16.622189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Разбитие датасета \n",
    "# \n",
    "# # Получаем индексы один раз (на основе имён файлов — одинаковы в обоих датасетах)\n",
    "# train_idx, val_idx, test_idx = split_dataset_by_groups(\n",
    "#     dataset=train_dataset_full,\n",
    "#     save_path=SPLIT_PATH\n",
    "# )"
   ],
   "id": "504508529fc9745e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:17.564986Z",
     "start_time": "2025-11-23T21:27:16.653215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загружаем сохранённые индексы\n",
    "split_data = torch.load(SPLIT_PATH)\n",
    "\n",
    "train_indices = split_data['train_indices']\n",
    "val_indices = split_data['val_indices']\n",
    "test_indices = split_data['test_indices']\n",
    "seed = split_data.get('seed', 'unknown')\n",
    "\n",
    "print(f\"  Train: {len(train_indices)}\")\n",
    "print(f\"  Val:   {len(val_indices)}\")\n",
    "print(f\"  Test:  {len(test_indices)}\")"
   ],
   "id": "8cc00b85833cb8b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: 216602\n",
      "  Val:   5972\n",
      "  Test:  5925\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:17.596522Z",
     "start_time": "2025-11-23T21:27:17.582006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаём подвыборки\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset = Subset(eval_dataset_full, val_indices)\n",
    "test_dataset = Subset(eval_dataset_full, test_indices)"
   ],
   "id": "8b6c7129bc797e78",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.082529Z",
     "start_time": "2025-11-23T21:27:17.613034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "item = train_dataset[34534]\n",
    "\n",
    "print(item['image'].shape)\n",
    "print(item['mask'].shape)\n",
    "\n",
    "print(item['image'].dtype)\n",
    "print(item['mask'].dtype)\n",
    "print(item['img_path'])\n",
    "print(item['mask_path'])"
   ],
   "id": "83e5f1ed61b947ef",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image too small: torch.Size([3, 512, 512])",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m34534\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\dataset.py:408\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[1;32m--> 408\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mF:\\Datasets\\DEFACTO\\tools\\dataclass.py:207\u001B[0m, in \u001B[0;36mForgerySegmentationDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    204\u001B[0m     mask \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(mask\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8))\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[1;32m--> 207\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage too small: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m: image,\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m\"\u001B[39m: mask,\n\u001B[0;32m    212\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(img_path),\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmask_path\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mstr\u001B[39m(mask_path)\n\u001B[0;32m    214\u001B[0m }\n",
      "\u001B[1;31mValueError\u001B[0m: Image too small: torch.Size([3, 512, 512])"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.098046Z",
     "start_time": "2025-11-23T21:10:46.179318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PVTv2B5ForForgerySegmentation(img_size=512)\n",
    "model"
   ],
   "id": "b847999bd44da03d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PVTv2B5ForForgerySegmentation(\n",
       "  (backbone): pvt_v2_b5(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1-2): 2 x Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0-39): 40 x Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (decode_head): FPNHead(\n",
       "    (scale_heads): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (conv_seg): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.101556700Z",
     "start_time": "2025-11-23T21:10:51.839031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загружаем чекпоинт\n",
    "checkpoint_path = \"model/pvt_v2_b5.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "# Удаляем классификационную голову (не нужна для сегментации)\n",
    "keys_to_remove = [k for k in state_dict.keys() if k.startswith('head')]\n",
    "for k in keys_to_remove:\n",
    "    del state_dict[k]\n",
    "\n",
    "# Загружаем в backbone\n",
    "missing_keys, unexpected_keys = model.backbone.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# Проверяем, что всё ок\n",
    "if len(unexpected_keys) == 0 and all('head' not in k for k in missing_keys):\n",
    "    print(\"Предобученные веса PVTv2-B5 успешно загружены!\")\n",
    "    if missing_keys:\n",
    "        print(f\"Не загружены ключи (ожидаемо для head): {missing_keys}\")\n",
    "else:\n",
    "    print(\"Ошибка при загрузке весов:\")\n",
    "    print(\"Unexpected keys:\", unexpected_keys)\n",
    "    print(\"Missing keys:\", missing_keys)"
   ],
   "id": "b7157ea1c9a998da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предобученные веса PVTv2-B5 успешно загружены!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.102556Z",
     "start_time": "2025-11-23T21:10:53.711313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bce_loss_fn = BinaryCrossEntropyLoss(loss_weight=1.0, avg_non_ignore=True)\n",
    "dice_loss_fn = DiceLoss(loss_weight=1.0, use_sigmoid=True)\n",
    "focal_loss_fn = FocalLoss(loss_weight=1.0)  # опционально\n",
    "\n",
    "optimizer = create_optimizer(\n",
    "    model,\n",
    "    lr=6e-5,\n",
    "    weight_decay=0.01,\n",
    "    head_lr_mult=10.0\n",
    ")\n",
    "\n",
    "# Планировщик\n",
    "scheduler = create_scheduler(\n",
    "    optimizer,\n",
    "    warmup_iters=1500,\n",
    "    total_iters=320000,\n",
    "    min_lr=0.0,\n",
    "    power=1.0\n",
    ")"
   ],
   "id": "758e843b3e89fe76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры разбиты на группы:\n",
      "   Backbone: 746 параметров\n",
      "   Norm:     322 параметров\n",
      "   Head:     30 параметров\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.102556Z",
     "start_time": "2025-11-23T21:20:48.762844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE_TRAIN,\n",
    "    num_workers=0,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    drop_last=DROP_LAST\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=SHUFFLE_VAL,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    drop_last=False  # на валидации лучше сохранять все примеры\n",
    ")"
   ],
   "id": "59e2395bf8c1ef57",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.103554700Z",
     "start_time": "2025-11-23T21:20:50.592968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = f\"runs/forgery_pvtv2_b5_{timestamp}\"\n",
    "checkpoint_dir = f\"{run_dir}/checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=run_dir)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "train_iter = iter(train_loader)\n",
    "metrics_val = BinarySegmentationMetrics(threshold=0.5)\n",
    "\n",
    "best_iou = 0.0"
   ],
   "id": "3f0f6bd53404540e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.103554700Z",
     "start_time": "2025-11-23T21:20:52.415120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for iter_idx in tqdm(range(1, MAX_ITERS + 1), desc=\"Training\"):\n",
    "\n",
    "    # --- Обучение ---\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    try:\n",
    "        batch = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        batch = next(train_iter)\n",
    "\n",
    "    # МАСКА: float32 + канал → [B, 1, H, W]\n",
    "    images = batch['image'].to(device, non_blocking=True)\n",
    "    masks = batch['mask'].to(device, non_blocking=True).float().unsqueeze(1)\n",
    "\n",
    "    pred = model(images)\n",
    "    loss = 0.5 * bce_loss_fn(pred, masks) + 1.0 * dice_loss_fn(pred, masks) + 0.8 * focal_loss_fn(pred, masks)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # --- Логирование ---\n",
    "    if iter_idx % LOG_INTERVAL == 0:\n",
    "        writer.add_scalar('Train/Loss', loss.item(), iter_idx)\n",
    "        writer.add_scalar('Train/LR', optimizer.param_groups[0]['lr'], iter_idx)\n",
    "\n",
    "    # --- Валидация ---\n",
    "    if iter_idx % VAL_INTERVAL == 0:\n",
    "        val_metrics = validate_epoch(\n",
    "            model, val_loader, metrics_val, device,\n",
    "            writer=writer,\n",
    "            epoch=iter_idx // VAL_INTERVAL,\n",
    "            visualize_every=VISUALIZE_EVERY\n",
    "        )\n",
    "\n",
    "        for name, value in val_metrics.items():\n",
    "            writer.add_scalar(f'Val/{name}', value, iter_idx)\n",
    "\n",
    "        print(f\"\\n[Iter {iter_idx}] Val — \" + \n",
    "              \" | \".join(f\"{k}: {v:.4f}\" for k, v in val_metrics.items()))\n",
    "\n",
    "        # --- Сохранение ЛУЧШЕЙ модели ---\n",
    "        current_iou = val_metrics['IoU_forgery']\n",
    "        if current_iou > best_iou:\n",
    "            best_iou = current_iou\n",
    "            best_path = f\"{checkpoint_dir}/best_model_iou_{current_iou:.4f}_iter_{iter_idx}.pth\"\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"Новая лучшая модель сохранена: {os.path.basename(best_path)}\")\n",
    "\n",
    "    # --- Сохранение ПОСЛЕДНЕЙ модели (каждые 10k) ---\n",
    "    if iter_idx % SAVE_INTERVAL == 0:\n",
    "        last_path = f\"{checkpoint_dir}/last_model_iter_{iter_idx}.pth\"\n",
    "        torch.save(model.state_dict(), last_path)\n",
    "\n",
    "# --- Финальное сохранение последней модели ---\n",
    "final_path = f\"{checkpoint_dir}/last_model_final.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "writer.close()"
   ],
   "id": "c7f5136b997b167e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/320000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: an illegal memory access was encountered\nSearch for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAcceleratorError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 8\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m     10\u001B[0m     train_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_loader)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    729\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    731\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 732\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    735\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    736\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    737\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    738\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    788\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m--> 790\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpin_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pin_memory_device\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    791\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:68\u001B[0m, in \u001B[0;36mpin_memory\u001B[1;34m(data, device)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mMutableMapping):\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m     clone \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mcopy(data)\n\u001B[0;32m     67\u001B[0m     clone\u001B[38;5;241m.\u001B[39mupdate(\n\u001B[1;32m---> 68\u001B[0m         {k: pin_memory(sample, device) \u001B[38;5;28;01mfor\u001B[39;00m k, sample \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m     69\u001B[0m     )\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m clone\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:68\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mMutableMapping):\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# The sequence type may have extra properties, so we can't just\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;66;03m# use `type(data)(...)` to create the new sequence.\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# Create a clone and update it if the sequence type is mutable.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m     clone \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mcopy(data)\n\u001B[0;32m     67\u001B[0m     clone\u001B[38;5;241m.\u001B[39mupdate(\n\u001B[1;32m---> 68\u001B[0m         {k: \u001B[43mpin_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k, sample \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m     69\u001B[0m     )\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m clone\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\PVTv2\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:57\u001B[0m, in \u001B[0;36mpin_memory\u001B[1;34m(data, device)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpin_memory\u001B[39m(data, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m---> 57\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpin_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m)):\n\u001B[0;32m     59\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "\u001B[1;31mAcceleratorError\u001B[0m: CUDA error: an illegal memory access was encountered\nSearch for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T21:27:18.104556800Z",
     "start_time": "2025-11-23T21:20:54.395102Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "73397971cce41a16",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
